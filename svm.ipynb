{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import  AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from torch import  nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_PS_train.csv\")\n",
    "le = LabelEncoder()\n",
    "df['encoded_labels'] = le.fit_transform(df['labels'])\n",
    "num_classes = len(le.classes_)\n",
    "val_df = pd.read_csv(\"cleaned_PS_dev.csv\")\n",
    "val_df['encoded_labels'] = le.transform(val_df['labels'])\n",
    "train_df=df\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/xlm-roberta-xl\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"facebook/xlm-roberta-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, tokenizer, texts, device, max_length=256):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for text in tqdm(texts, desc=\"Extracting Embeddings\"):\n",
    "            encoding = tokenizer(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            ).to(device)\n",
    "\n",
    "            # Extract embeddings from the model\n",
    "            outputs = model(**encoding, output_hidden_states=True)\n",
    "            hidden_states = outputs.hidden_states[-1]  # Last hidden layer\n",
    "            embedding = hidden_states.mean(dim=1).squeeze(0)  # Mean pooling\n",
    "            embeddings.append(embedding.cpu().numpy())\n",
    "\n",
    "    return torch.tensor(embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Embeddings: 100%|██████████| 3916/3916 [01:09<00:00, 56.04it/s]\n",
      "C:\\Users\\nithi\\AppData\\Local\\Temp\\ipykernel_4060\\220809976.py:22: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  return torch.tensor(embeddings)\n",
      "Extracting Embeddings: 100%|██████████| 436/436 [00:08<00:00, 53.33it/s]\n",
      "c:\\Users\\nithi\\anaconda3\\envs\\College\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nithi\\anaconda3\\envs\\College\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nithi\\anaconda3\\envs\\College\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3463\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         Negative       0.00      0.00      0.00        41\n",
      "          Neutral       0.00      0.00      0.00        64\n",
      "None of the above       1.00      0.47      0.64        17\n",
      "      Opinionated       0.33      0.97      0.49       136\n",
      "         Positive       0.00      0.00      0.00        58\n",
      "        Sarcastic       0.48      0.14      0.22        79\n",
      "    Substantiated       0.00      0.00      0.00        41\n",
      "\n",
      "         accuracy                           0.35       436\n",
      "        macro avg       0.26      0.23      0.19       436\n",
      "     weighted avg       0.23      0.35      0.22       436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Embeddings: 100%|██████████| 1/1 [00:00<00:00, 20.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: Opinionated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_embeddings = extract_embeddings(model, tokenizer, train_df['content'].values, device)\n",
    "val_embeddings = extract_embeddings(model, tokenizer, val_df['content'].values, device)\n",
    "\n",
    "# Train an SVM model\n",
    "svm = SVC(kernel='linear', probability=True)\n",
    "svm.fit(train_embeddings, train_df['encoded_labels'].values)\n",
    "\n",
    "# Validate the SVM model\n",
    "val_predictions = svm.predict(val_embeddings)\n",
    "val_accuracy = accuracy_score(val_df['encoded_labels'].values, val_predictions)\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "print(classification_report(val_df['encoded_labels'].values, val_predictions, target_names=le.classes_))\n",
    "\n",
    "# Function for inference with the SVM model\n",
    "def predict_svm(text, model, tokenizer, svm, device, max_length=256):\n",
    "    embedding = extract_embeddings(model, tokenizer, [text], device, max_length=max_length)\n",
    "    prediction = svm.predict(embedding)\n",
    "    return le.inverse_transform(prediction)\n",
    "\n",
    "# Example inference\n",
    "text = \"தென்காசி தொகுதி புதிய தமிழகம் கட்சி வேட்பாளர் டாக்டர்\"\n",
    "predicted_label = predict_svm(text, model, tokenizer, svm, device)\n",
    "print(f\"Predicted Label: {predicted_label[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"cleaned_PS_train.csv\")\n",
    "le = LabelEncoder()\n",
    "df['encoded_labels'] = le.fit_transform(df['labels'])\n",
    "num_classes = len(le.classes_)\n",
    "val_df = pd.read_csv(\"cleaned_PS_dev.csv\")\n",
    "val_df['encoded_labels'] = le.transform(val_df['labels'])\n",
    "train_df=df\n",
    "# Load tokenizer and model for LaBSE\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\", cache_dir='models/LaBSE')\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/LaBSE\", cache_dir='models/LaBSE').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Embeddings: 100%|██████████| 4352/4352 [01:07<00:00, 64.58it/s]\n",
      "Extracting Embeddings: 100%|██████████| 544/544 [00:09<00:00, 58.41it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_embeddings(model, tokenizer, texts, device, max_length=256):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for text in tqdm(texts, desc=\"Extracting Embeddings\"):\n",
    "            encoding = tokenizer(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            ).to(device)\n",
    "\n",
    "            # Extract embeddings from the model\n",
    "            outputs = model(**encoding, output_hidden_states=True)\n",
    "            hidden_states = outputs.hidden_states[-1]  # Last hidden layer\n",
    "            embedding = hidden_states.mean(dim=1).squeeze(0)  # Mean pooling\n",
    "            embeddings.append(embedding.cpu().numpy())\n",
    "\n",
    "    return torch.tensor(embeddings)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_embeddings = extract_embeddings(model, tokenizer, train_df['content'].values, device)\n",
    "val_embeddings = extract_embeddings(model, tokenizer, val_df['content'].values, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.2996\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         Negative       0.10      0.10      0.10        51\n",
      "          Neutral       0.24      0.20      0.22        84\n",
      "None of the above       0.84      0.80      0.82        20\n",
      "      Opinionated       0.33      0.47      0.39       153\n",
      "         Positive       0.18      0.16      0.17        69\n",
      "        Sarcastic       0.39      0.35      0.37       115\n",
      "    Substantiated       0.10      0.04      0.05        52\n",
      "\n",
      "         accuracy                           0.30       544\n",
      "        macro avg       0.31      0.30      0.30       544\n",
      "     weighted avg       0.28      0.30      0.29       544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Embeddings: 100%|██████████| 1/1 [00:00<00:00, 42.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', probability=True)\n",
    "svm.fit(train_embeddings, train_df['encoded_labels'].values)\n",
    "\n",
    "# Validate the SVM model\n",
    "val_predictions = svm.predict(val_embeddings)\n",
    "val_accuracy = accuracy_score(val_df['encoded_labels'].values, val_predictions)\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "print(classification_report(val_df['encoded_labels'].values, val_predictions, target_names=le.classes_))\n",
    "\n",
    "# Function for inference with the SVM model\n",
    "def predict_svm(text, model, tokenizer, svm, device, max_length=256):\n",
    "    embedding = extract_embeddings(model, tokenizer, [text], device, max_length=max_length)\n",
    "    prediction = svm.predict(embedding)\n",
    "    return le.inverse_transform(prediction)\n",
    "\n",
    "# Example inference\n",
    "text = \"தென்காசி தொகுதி புதிய தமிழகம் கட்சி வேட்பாளர் டாக்டர்\"\n",
    "predicted_label = predict_svm(text, model, tokenizer, svm, device)\n",
    "print(f\"Predicted Label: {predicted_label[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nithi\\anaconda3\\envs\\College\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nithi\\anaconda3\\envs\\College\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nithi\\anaconda3\\envs\\College\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3419\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         Negative       0.00      0.00      0.00        51\n",
      "          Neutral       0.00      0.00      0.00        84\n",
      "None of the above       0.90      0.90      0.90        20\n",
      "      Opinionated       0.31      0.91      0.46       153\n",
      "         Positive       0.00      0.00      0.00        69\n",
      "        Sarcastic       0.42      0.25      0.32       115\n",
      "    Substantiated       0.00      0.00      0.00        52\n",
      "\n",
      "         accuracy                           0.34       544\n",
      "        macro avg       0.23      0.29      0.24       544\n",
      "     weighted avg       0.21      0.34      0.23       544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Embeddings: 100%|██████████| 1/1 [00:00<00:00, 49.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: Opinionated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "svm2 = SVC(kernel='rbf', probability=True)\n",
    "svm2.fit(train_embeddings, train_df['encoded_labels'].values)\n",
    "\n",
    "# Validate the SVM2 model\n",
    "val_predictions = svm2.predict(val_embeddings)\n",
    "val_accuracy = accuracy_score(val_df['encoded_labels'].values, val_predictions)\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "print(classification_report(val_df['encoded_labels'].values, val_predictions, target_names=le.classes_))\n",
    "\n",
    "# Function for inference with the SVM2 model\n",
    "def predict_svm2(text, model, tokenizer, svm2, device, max_length=256):\n",
    "    embedding = extract_embeddings(model, tokenizer, [text], device, max_length=max_length)\n",
    "    prediction = svm2.predict(embedding)\n",
    "    return le.inverse_transform(prediction)\n",
    "\n",
    "# Example inference\n",
    "text = \"தென்காசி தொகுதி புதிய தமிழகம் கட்சி வேட்பாளர் டாக்டர்\"\n",
    "predicted_label = predict_svm2(text, model, tokenizer, svm2, device)\n",
    "print(f\"Predicted Label: {predicted_label[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Embeddings: 100%|██████████| 544/544 [00:07<00:00, 72.93it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"cleaned_PS_test.csv\")\n",
    "\n",
    "embedding = extract_embeddings(model, tokenizer, test_df['content'].values, device)\n",
    "\n",
    "# Predict with the SVM model\n",
    "predictions = svm.predict(embedding)\n",
    "test_df['predicted_labels'] = le.inverse_transform(predictions)\n",
    "\n",
    "test_df[['Id','predicted_labels']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>predicted_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PS_01</td>\n",
       "      <td>Opinionated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PS_02</td>\n",
       "      <td>Opinionated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PS_03</td>\n",
       "      <td>Opinionated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PS_04</td>\n",
       "      <td>Opinionated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PS_05</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>PS_540</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>PS_541</td>\n",
       "      <td>Opinionated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>PS_542</td>\n",
       "      <td>Opinionated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>PS_543</td>\n",
       "      <td>Opinionated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>PS_544</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>544 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id predicted_labels\n",
       "0     PS_01      Opinionated\n",
       "1     PS_02      Opinionated\n",
       "2     PS_03      Opinionated\n",
       "3     PS_04      Opinionated\n",
       "4     PS_05         Positive\n",
       "..      ...              ...\n",
       "539  PS_540         Negative\n",
       "540  PS_541      Opinionated\n",
       "541  PS_542      Opinionated\n",
       "542  PS_543      Opinionated\n",
       "543  PS_544         Positive\n",
       "\n",
       "[544 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['Id','predicted_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49f91a33a164fcfa81644428a1513d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/206 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6a5ccc80bd461699ea89841f19ae3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbbe344accd40438a6bd2587185fa2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/3.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5feee33294440ca97a1e580e4ef7360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/113 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1bba4e73f5469c84f12511855b232b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/953M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Embeddings: 100%|██████████| 3916/3916 [00:51<00:00, 76.17it/s]\n",
      "Extracting Embeddings: 100%|██████████| 436/436 [00:06<00:00, 66.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3119\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         Negative       0.00      0.00      0.00        41\n",
      "          Neutral       0.00      0.00      0.00        64\n",
      "None of the above       0.00      0.00      0.00        17\n",
      "      Opinionated       0.31      1.00      0.48       136\n",
      "         Positive       0.00      0.00      0.00        58\n",
      "        Sarcastic       0.00      0.00      0.00        79\n",
      "    Substantiated       0.00      0.00      0.00        41\n",
      "\n",
      "         accuracy                           0.31       436\n",
      "        macro avg       0.04      0.14      0.07       436\n",
      "     weighted avg       0.10      0.31      0.15       436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nithi\\anaconda3\\envs\\College\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nithi\\anaconda3\\envs\\College\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nithi\\anaconda3\\envs\\College\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"cleaned_PS_train.csv\")\n",
    "le = LabelEncoder()\n",
    "df['encoded_labels'] = le.fit_transform(df['labels'])\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42, stratify=df['encoded_labels'])\n",
    "\n",
    "# Load tokenizer and model for MURIL\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\", cache_dir='models/muril')\n",
    "model = AutoModel.from_pretrained(\"google/muril-base-cased\", cache_dir='models/muril').to('cuda')\n",
    "\n",
    "# Function to extract embeddings\n",
    "def extract_embeddings(model, tokenizer, texts, device, max_length=256):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for text in tqdm(texts, desc=\"Extracting Embeddings\"):\n",
    "            encoding = tokenizer(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            ).to(device)\n",
    "\n",
    "            # Extract embeddings\n",
    "            outputs = model(**encoding, output_hidden_states=True)\n",
    "            hidden_states = outputs.hidden_states[-1]  # Last hidden layer\n",
    "            embedding = hidden_states.mean(dim=1).squeeze(0)  # Mean pooling\n",
    "            embeddings.append(embedding.cpu().numpy())\n",
    "\n",
    "    return torch.tensor(embeddings)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_embeddings = extract_embeddings(model, tokenizer, train_df['content'].values, device)\n",
    "val_embeddings = extract_embeddings(model, tokenizer, val_df['content'].values, device)\n",
    "\n",
    "# Train an SVM model\n",
    "svm = SVC(kernel='linear', probability=True)\n",
    "svm.fit(train_embeddings, train_df['encoded_labels'].values)\n",
    "\n",
    "# Validate the SVM model\n",
    "val_predictions = svm.predict(val_embeddings)\n",
    "val_accuracy = accuracy_score(val_df['encoded_labels'].values, val_predictions)\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "print(classification_report(val_df['encoded_labels'].values, val_predictions, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Embeddings: 100%|██████████| 3916/3916 [01:07<00:00, 58.02it/s]\n",
      "Extracting Embeddings: 100%|██████████| 436/436 [00:09<00:00, 47.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3188\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         Negative       0.00      0.00      0.00        41\n",
      "          Neutral       0.26      0.11      0.15        64\n",
      "None of the above       1.00      0.76      0.87        17\n",
      "      Opinionated       0.33      0.76      0.46       136\n",
      "         Positive       0.16      0.05      0.08        58\n",
      "        Sarcastic       0.22      0.15      0.18        79\n",
      "    Substantiated       0.00      0.00      0.00        41\n",
      "\n",
      "         accuracy                           0.32       436\n",
      "        macro avg       0.28      0.26      0.25       436\n",
      "     weighted avg       0.24      0.32      0.24       436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model for IndicBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\", cache_dir='models/indic-bert')\n",
    "model = AutoModel.from_pretrained(\"ai4bharat/indic-bert\", cache_dir='models/indic-bert').to('cuda')\n",
    "\n",
    "# Function to extract embeddings remains the same\n",
    "train_embeddings = extract_embeddings(model, tokenizer, train_df['content'].values, device)\n",
    "val_embeddings = extract_embeddings(model, tokenizer, val_df['content'].values, device)\n",
    "\n",
    "# Train an SVM model\n",
    "svm = SVC(kernel='linear', probability=True)\n",
    "svm.fit(train_embeddings, train_df['encoded_labels'].values)\n",
    "\n",
    "# Validate the SVM model\n",
    "val_predictions = svm.predict(val_embeddings)\n",
    "val_accuracy = accuracy_score(val_df['encoded_labels'].values, val_predictions)\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "print(classification_report(val_df['encoded_labels'].values, val_predictions, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"nvidia/embed_sentence_transformer_v2\", cache_dir='models/nvidia_embed_v2')\n",
    "# model = AutoModel.from_pretrained(\"nvidia/embed_sentence_transformer_v2\", cache_dir='models/nvidia_embed_v2').to('cuda')\n",
    "model = SentenceTransformer('sentence-transformers/stsb-xlm-r-multilingual')\n",
    "\n",
    "# Function to extract embeddings\n",
    "def extract_embeddings(model, tokenizer, texts, device, max_length=256):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for text in tqdm(texts, desc=\"Extracting Embeddings\"):\n",
    "            # encoding = tokenizer(\n",
    "            #     text,\n",
    "            #     add_special_tokens=True,\n",
    "            #     max_length=max_length,\n",
    "            #     padding='max_length',\n",
    "            #     truncation=True,\n",
    "            #     return_attention_mask=True,\n",
    "            #     return_tensors='pt'\n",
    "            # ).to(device)\n",
    "\n",
    "            # Extract embeddings from the model\n",
    "            outputs = model.encode(text)\n",
    "            hidden_states = outputs.hidden_states[-1]  # Last hidden layer\n",
    "            embedding = hidden_states.mean(dim=1).squeeze(0)  # Mean pooling\n",
    "            embeddings.append(embedding.cpu().numpy())\n",
    "\n",
    "    return torch.tensor(embeddings)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Embeddings: 100%|██████████| 4352/4352 [01:06<00:00, 65.45it/s]\n",
      "Extracting Embeddings: 100%|██████████| 544/544 [00:08<00:00, 64.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.2904\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         Negative       0.16      0.14      0.15        51\n",
      "          Neutral       0.15      0.12      0.13        84\n",
      "None of the above       0.90      0.90      0.90        20\n",
      "      Opinionated       0.34      0.58      0.43       153\n",
      "         Positive       0.12      0.09      0.10        69\n",
      "        Sarcastic       0.33      0.23      0.27       115\n",
      "    Substantiated       0.11      0.06      0.07        52\n",
      "\n",
      "         accuracy                           0.29       544\n",
      "        macro avg       0.30      0.30      0.29       544\n",
      "     weighted avg       0.26      0.29      0.26       544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to extract embeddings\n",
    "def extract_embeddings(model, texts, device):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    for text in tqdm(texts, desc=\"Extracting Embeddings\"):\n",
    "        # Extract embeddings using the SentenceTransformer model\n",
    "        embedding = model.encode(text, convert_to_tensor=True, device=device)\n",
    "        embeddings.append(embedding.cpu().numpy())  # Convert to numpy array for compatibility\n",
    "\n",
    "    return torch.tensor(embeddings)\n",
    "\n",
    "train_embeddings = extract_embeddings(model, train_df['content'].values, device)\n",
    "val_embeddings = extract_embeddings(model, val_df['content'].values, device)\n",
    "\n",
    "# Train an SVM model\n",
    "svm = SVC(kernel='linear', probability=True)\n",
    "svm.fit(train_embeddings, train_df['encoded_labels'].values)\n",
    "\n",
    "# Validate the SVM model\n",
    "val_predictions = svm.predict(val_embeddings)\n",
    "val_accuracy = accuracy_score(val_df['encoded_labels'].values, val_predictions)\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "print(classification_report(val_df['encoded_labels'].values, val_predictions, target_names=le.classes_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1224a43dd3c4d269b02d0c3cc3fcd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eafee9372a404694b83c89ee6ac2a90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:  17%|#6        | 849M/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd110216a1746cebec99e0dd5898415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ecc276c1e014c8c8474896c44f84f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd88d971abd84070b95268790aba6b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/789M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained('nvidia/NV-Embed-v2', trust_remote_code=True, cache_dir='models')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "College",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
